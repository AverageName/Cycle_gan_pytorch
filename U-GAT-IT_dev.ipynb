{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from models.CycleGAN import *\n",
    "from datasets.UnalignedDataset import UnalignedDataset\n",
    "from utils.utils import ImageBuffer, set_requires_grad, tensor_to_image, save_cyclegan_model, get_activation, get_norm_module, Identity\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 3, 256, 256)\n",
    "torch.mean(a.view(a.size(0), a.size(1), -1), 2).unsqueeze(2).unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(AdaLIN, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.rho = nn.Parameter(torch.empty(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.9)\n",
    "    \n",
    "    def forward(self, inputs, gamma, beta):\n",
    "        #inputs_in_mean, inputs_in_var = torch.mean(inputs, dim=[2, 3], keep_dim=True), torch.var(inputs, dim=[2, 3], keep_dim=True)\n",
    "        inputs_in_mean = torch.mean(inputs.view(inputs.size(0), inputs.size(1), -1), 2).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_in_var = torch.var(inputs.view(inputs.size(0), inputs.size(1), -1), 2).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_in = (inputs - inputs_in_mean) / torch.sqrt((inputs_in_var + self.eps))\n",
    "        #inputs_ln_mean, inputs_ln_var = torch.mean(inputs, dim[1, 2, 3], keep_dim=True), torch.var(inputs, dim=[1, 2, 3], keep_dim=True)\n",
    "        inputs_ln_mean = torch.mean(inputs.view(inputs.size(0), -1), 1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_ln_var = torch.var(inputs.view(inputs.size(0), -1), 1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_ln = (inputs - inputs_ln_mean) / torch.sqrt((inputs_ln_var + self.eps))\n",
    "        \n",
    "        out = self.rho.expand(inputs.shape[0], -1, -1, -1) * inputs_in + \\\n",
    "              ((1 - self.rho).expand(inputs.shape[0], -1, -1, -1) * inputs_ln)\n",
    "        \n",
    "        return gamma.unsqueeze(2).unsqueeze(3) * out + beta.unsqueeze(2).unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(LIN, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.rho = nn.Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.gamma = nn.Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.Tensor(1, num_features, 1, 1))\n",
    "        self.rho.data.fill_(0.0)\n",
    "        self.gamma.data.fill_(1.0)\n",
    "        self.beta.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #inputs_in_mean, inputs_in_var = torch.mean(inputs, dim=[2, 3], keep_dim=True), torch.var(inputs, dim=[2, 3], keep_dim=True)\n",
    "        inputs_in_mean = torch.mean(inputs.view(inputs.size(0), inputs.size(1), -1), 2).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_in_var = torch.var(inputs.view(inputs.size(0), inputs.size(1), -1), 2).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_in = (inputs - inputs_in_mean) / torch.sqrt((inputs_in_var + self.eps))\n",
    "        #inputs_ln_mean, inputs_ln_var = torch.mean(inputs, dim[1, 2, 3], keep_dim=True), torch.var(inputs, dim=[1, 2, 3], keep_dim=True)\n",
    "        inputs_ln_mean = torch.mean(inputs.view(inputs.size(0), -1), 1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_ln_var = torch.var(inputs.view(inputs.size(0), -1), 1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        inputs_ln = (inputs - inputs_ln_mean) / torch.sqrt((inputs_ln_var + self.eps))\n",
    "        \n",
    "        out = self.rho.expand(inputs.shape[0], -1, -1, -1) * inputs_in + \\\n",
    "                ((1 - self.rho).expand(inputs.shape[0], -1, -1, -1) * inputs_ln)\n",
    "        \n",
    "        return gamma.expand(inputs.shape[0], -1, -1, -1) * out + beta.expand(inputs.shape[0], -1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLINResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, kernel_size, activation, pad_type):\n",
    "        super(AdaLINResBlock, self).__init__()\n",
    "        \n",
    "        if pad_type == \"reflection\":\n",
    "            self.pad1 = nn.ReflectionPad2d(kernel_size // 2)\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size)\n",
    "            self.pad2 = nn.ReflectionPad2d(kernel_size // 2)\n",
    "            self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size)\n",
    "        elif pad_type == \"zeros\":\n",
    "            self.pad1 = None\n",
    "            self.pad2 = None\n",
    "            self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels,\n",
    "                                   kernel_size=kernel_size, padding=kernel_size//2)\n",
    "            self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels,\n",
    "                                   kernel_size=kernel_size, padding=kernel_size//2)\n",
    "            \n",
    "        self.norm1 = AdaLIN(in_channels)\n",
    "        self.norm2 = AdaLIN(in_channels)\n",
    "        self.act = get_activation(activation)\n",
    "    \n",
    "    def forward(self, inputs, gamma, beta):\n",
    "        out = inputs\n",
    "        if self.pad1 is not None:\n",
    "            out = self.pad1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(self.norm1(out, gamma, beta))\n",
    "        if self.pad2 is not None:\n",
    "            out = self.pad2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out, gamma, beta)\n",
    "        return out + inputs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, kernel_size, activation, norm_type, pad_type):\n",
    "        super(UpsampleConvBlock, self).__init__()\n",
    "        \n",
    "        if pad_type == \"reflection\":\n",
    "            self.pad = nn.ReflectionPad2d(kernel_size // 2)\n",
    "            self.conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels//2,\n",
    "                              kernel_size=kernel_size)\n",
    "        elif pad_type == \"zeros\":\n",
    "            self.pad = None\n",
    "            self.conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels//2,\n",
    "                              kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        self.act = get_activation(activation)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.norm = get_norm_module(norm_type)(in_channels//2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        if self.pad is not None:\n",
    "            out = self.pad(out)\n",
    "        out = self.conv(out)\n",
    "        out = self.norm(out)\n",
    "        out = self.act(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, img_size, num_enc_blocks, num_enc_res_blocks, num_dec_upsample_blocks,\n",
    "                 num_dec_res_blocks, norm_type, pad_type):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        dims = 64\n",
    "        self.conv1 = ConvNormRelu(in_channels=in_channels, out_channels=dims, kernel_size=7, padding=(3, pad_type),\n",
    "                                  norm=norm_type, leaky=False)\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_enc_blocks - 1):\n",
    "            prev_dims = dims\n",
    "            dims = min(dims * 2, 256)\n",
    "            self.convs.append(ConvNormRelu(in_channels=prev_dims, out_channels=dims, kernel_size=3,\n",
    "                                           padding=(1, pad_type), norm=norm_type, stride=2))\n",
    "            \n",
    "        self.res_blocks = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_enc_res_blocks):\n",
    "            self.res_blocks.append(ResBlock(in_planes=dims, kernel_size=3, padding=(1, pad_type), norm=norm_type))\n",
    "            \n",
    "        \n",
    "        self.gap_fc = nn.Linear(dims, 1, bias=False)\n",
    "        self.gmp_fc = nn.Linear(dims, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels=dims * 2, out_channels=dims, kernel_size=1, stride=1)\n",
    "        \n",
    "        \n",
    "        MLP = [nn.Linear(in_features=dims * (img_size // 2 ** (num_enc_blocks - 1)) ** 2, out_features=dims, bias=False),\n",
    "               nn.ReLU(True),\n",
    "               nn.Linear(in_features=dims, out_features=dims, bias=False),\n",
    "               nn.ReLU(True)]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*MLP)\n",
    "        self.gamma = nn.Linear(in_features=dims, out_features=dims, bias=False)\n",
    "        self.beta = nn.Linear(in_features=dims, out_features=dims, bias=False)\n",
    "        \n",
    "        #Decoder\n",
    "        self.decoder_res_blocks = nn.ModuleList()\n",
    "        for _ in range(num_dec_res_blocks):\n",
    "            self.decoder_res_blocks.append(AdaLINResBlock(in_channels=dims, kernel_size=3,\n",
    "                                                      activation='relu', pad_type=\"reflection\"))\n",
    "        \n",
    "        self.upsample_blocks = nn.ModuleList()\n",
    "        for _ in range(num_dec_upsample_blocks):\n",
    "            self.upsample_blocks.append(UpsampleConvBlock(in_channels=dims, kernel_size=3, activation=\"relu\",\n",
    "                                                         norm_type=\"lin\", pad_type=\"reflection\"))\n",
    "            dims = dims // 2\n",
    "        \n",
    "        self.pad_last_conv = nn.ReflectionPad2d(3)\n",
    "        self.last_conv = nn.Conv2d(in_channels=dims, out_channels=3, kernel_size=7, stride=1, bias=False)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #Extracting features\n",
    "        out = self.conv1(inputs)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            out = conv(out)\n",
    "            \n",
    "        for res_block in self.res_blocks:\n",
    "            out = res_block(out)\n",
    "            \n",
    "            \n",
    "        #Global Average and Max Pooling\n",
    "        gap = F.adaptive_avg_pool2d(out, 1)\n",
    "        gap_logits = self.gap_fc(gap.view(out.shape[0], -1))\n",
    "        gap_fc_weigths = list(self.gap_fc.parameters())[0]\n",
    "        gap = gap_fc_weigths.view(gap_fc_weigths.size(0), gap_fc_weigths.size(1), 1, 1) * out\n",
    "        \n",
    "        \n",
    "        gmp = F.adaptive_max_pool2d(out, 1)\n",
    "        gmp_logits = self.gmp_fc(gmp.view(out.shape[0], -1))\n",
    "        gmp_fc_weights = list(self.gmp_fc.parameters())[0]\n",
    "        gmp = gmp_fc_weights.view(gmp_fc_weights.size(0), gmp_fc_weights.size(1), 1, 1) * out\n",
    "        \n",
    "        gmp_gap_logits = torch.cat([gmp_logits, gap_logits], 1)\n",
    "        \n",
    "        gmp_gap = torch.cat([gmp, gap], 1)\n",
    "        \n",
    "        out = F.relu(self.conv2(gmp_gap))\n",
    "        cam = out\n",
    "        \n",
    "        #Calculating beta and gamma for AdaLIN\n",
    "        out = self.mlp(out.view(out.size(0), -1))\n",
    "        \n",
    "        gamma = self.gamma(out)\n",
    "        beta = self.beta(out)\n",
    "        \n",
    "        out = cam\n",
    "        for res_block in self.decoder_res_blocks:\n",
    "            out = res_block(out, gamma, beta)\n",
    "        \n",
    "        for upsample_block in self.upsample_blocks:\n",
    "            out = upsample_block(out)\n",
    "        \n",
    "        out = self.pad_last_conv(out)\n",
    "        return F.tanh(self.last_conv(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpakhom1/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = Generator(3, 256, 3, 4, 2, 4, \"instance\", \"reflection\").cuda()\n",
    "inputs = torch.randn(1, 3, 256, 256).cuda()\n",
    "print(model(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1.post2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGan(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, num_downsample, norm_type, pad_type):\n",
    "        super(PatchGan, self).__init__()\n",
    "        \n",
    "        dims = 64\n",
    "        self.conv1 = ConvNormRelu(in_channels=in_channels, out_channels=dims, kernel_size=4,\n",
    "                                  padding=(1, pad_type), stride=2, leaky=True, norm=\"sn\")\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_downsample):\n",
    "            prev_dims = dims\n",
    "            dims = dims * 2\n",
    "            self.convs.append(ConvNormRelu(in_channels=prev_dims, out_channels=dims, kernel_size=4,\n",
    "                                  padding=(1, pad_type), stride=2, leaky=True, norm=\"sn\"))\n",
    "        \n",
    "        prev_dims = dims\n",
    "        dims = dims * 2\n",
    "        \n",
    "        self.conv2 = ConvNormRelu(in_channels=prev_dims, out_channels=dims, kernel_size=4,\n",
    "                                  padding=(1, pad_type), stride=1, leaky=True, norm=\"sn\")\n",
    "        \n",
    "        self.gap_fc = nn.Linear(dims, 1)\n",
    "        self.gmp_fc = nn.Linear(dims, 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=dims * 2, out_channels=dims, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.pad_last_conv = nn.ReflectionPad2d(1)\n",
    "        self.last_conv = nn.Conv2d(in_channels=dims, out_channels=1, kernel_size=4, stride=1)\n",
    "        self.norm_last_conv = get_norm_module(\"sn\")(1)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = self.conv1(inputs)\n",
    "        for conv in self.convs:\n",
    "            out = conv(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        gap = F.adaptive_avg_pool2d(out, 1)\n",
    "        gap_logits = self.gap_fc(gap.view(gap.size(0), -1))\n",
    "        gap_fc_weights = list(self.gap_fc.parameters())[0]\n",
    "        gap = out * gap_fc_weights.view(gap_fc_weights.size(0), gap_fc_weights.size(1), 1, 1)\n",
    "        \n",
    "\n",
    "        gmp = F.adaptive_max_pool2d(out, 1)\n",
    "        gmp_logits = self.gmp_fc(gmp.view(gmp.size(0), -1))\n",
    "        gmp_fc_weights = list(self.gmp_fc.parameters())[0]\n",
    "        gmp = out * gmp_fc_weights.view(gmp_fc_weights.size(0), gmp_fc_weights.size(1), 1, 1)\n",
    "        \n",
    "        \n",
    "        gap_gmp_logits = torch.cat([gap, gmp], 1)\n",
    "        gap_gmp = torch.cat([gap, gmp], 1)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv3(gap_gmp), negative_slope=0.2)\n",
    "        \n",
    "        out = self.pad_last_conv(out)\n",
    "        out = self.last_conv(out)\n",
    "        out = self.norm_last_conv(out)\n",
    "        \n",
    "        return out, gap_gmp_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
