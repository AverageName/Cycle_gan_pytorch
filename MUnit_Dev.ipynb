{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from models.CycleGAN import *\n",
    "from datasets.UnalignedDataset import UnalignedDataset\n",
    "from utils.utils import ImageBuffer, set_requires_grad, tensor_to_image, save_cyclegan_model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channels, num_blocks):\n",
    "        super(ContentEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvNormRelu(in_channels=num_channels, out_channels=64,\n",
    "                                  kernel_size=7, padding=(3, \"zeros\"), leaky=False, norm='instance')\n",
    "        self.conv2 = ConvNormRelu(in_channels=64, out_channels=128, \n",
    "                                  kernel_size=4, padding=(1, \"zeros\"), stride=2, leaky=False, norm='instance')\n",
    "        self.conv3 = ConvNormRelu(in_channels=128, out_channels=256, \n",
    "                                 kernel_size=4, padding=(1, \"zeros\"), stride=2, leaky=False, norm='instance')\n",
    "        self.blocks = nn.ModuleList()\n",
    "        dims = 256\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(ResBlock(in_planes=dims, kernel_size=3, padding=(1, \"reflection\"), norm=\"instance\"))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channels, style_dims):\n",
    "        super(StyleEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvNormRelu(in_channels=num_channels, out_channels=64,\n",
    "                                  kernel_size=7, padding=(3, \"zeros\"), leaky=False, norm='instance')\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        dims = 64\n",
    "        prev_dims = 0\n",
    "        n_convs = 4\n",
    "        \n",
    "        for _ in range(n_convs):\n",
    "            prev_dims = dims\n",
    "            dims = min(dims * 2, 256)\n",
    "            \n",
    "            self.convs.append(ConvNormRelu(in_channels=prev_dims, out_channels=dims, \n",
    "                                  kernel_size=4, padding=(1, \"zeros\"), stride=2, leaky=False, norm='instance'))\n",
    "        \n",
    "        self.conv_fc = nn.Conv2d(dims, style_dims, kernel_size=1, stride=1, padding=0)  \n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        out = self.conv1(inputs)\n",
    "        for conv in self.convs:\n",
    "            out = conv(out)\n",
    "            \n",
    "        #Fastest version of Global Average Pooling\n",
    "        out = torch.mean(out.view(out.size(0), out.size(1), -1), dim=2)\n",
    "        out = self.conv_fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nvidia implementation\n",
    "class AdaptiveInstanceNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(AdaptiveInstanceNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        # weight and bias are dynamically assigned\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        # just dummy buffers, not used\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.weight is not None and self.bias is not None, \"Please assign weight and bias before calling AdaIN!\"\n",
    "        b, c = x.size(0), x.size(1)\n",
    "        running_mean = self.running_mean.repeat(b)\n",
    "        running_var = self.running_var.repeat(b)\n",
    "\n",
    "        # Apply instance norm\n",
    "        x_reshaped = x.contiguous().view(1, b * c, *x.size()[2:])\n",
    "\n",
    "        out = F.batch_norm(\n",
    "            x_reshaped, running_mean, running_var, self.weight, self.bias,\n",
    "            True, self.momentum, self.eps)\n",
    "\n",
    "        return out.view(b, c, *x.size()[2:])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + str(self.num_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        n_blocks = 4\n",
    "        for _ in range(n_blocks):\n",
    "            self.blocks.append(ResBlock(in_planes=in_channels, kernel_size=3,\n",
    "                                        padding=(1, \"reflection\"), norm=\"adain\"))\n",
    "        n_blocks = 2\n",
    "        self.upsample_blocks = nn.ModuleList()\n",
    "        prev_dims = 0\n",
    "        dims = 256\n",
    "        for _ in range(n_blocks):\n",
    "            prev_dims = dims\n",
    "            dims = dims // 2\n",
    "            self.upsample_blocks.append(nn.Upsample(scale_factor=2))\n",
    "            self.upsample_blocks.append(ConvNormRelu(in_channels=prev_dims, out_channels=dims,\n",
    "                                                     kernel_size=5, padding=(2, \"reflection\"), stride=1, norm=\"ln\"))\n",
    "            \n",
    "        self.last_layer = ConvNormRelu(in_channels=dims, out_channels=3, kernel_size=7,\n",
    "                                      padding=(3, \"reflection\"), stride=1, norm=None)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out = inputs\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        for block in self.upsample_blocks:\n",
    "            out = block(out)\n",
    "        return F.tanh(self.last_layer(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
